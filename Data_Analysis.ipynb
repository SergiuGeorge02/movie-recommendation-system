{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I read the .ndjson file line-by-line to avoid memory issues.\n",
    "Then I load a subset of 1000 shows into a dataframe for faster and easier analysis due to the fact that the dataset is big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oJZKfJ678w-V",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "sample_size = 1000\n",
    "data = []\n",
    "\n",
    "with open(\"data.ndjson\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= sample_size:\n",
    "            break\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am printing the columns from the datasert, the shape of it and I am also printing the missing values on eacch column in order to see what data needs to be cleaned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['id', '_rid', '_self', '_etag', '_attachments', 'url', 'name', 'type', 'language', 'genres', 'status', 'runtime', 'averageRuntime', 'premiered', 'ended', 'officialSite', 'schedule', 'rating', 'weight', 'network', 'webChannel', 'dvdCountry', 'externals', 'image', 'summary', 'updated', '_links', '_embedded', 'seasons', 'wikipedia_url', 'wikiquote_url', 'metacritic_url', 'eztv_url', '_ts', 'wikipedia', 'wikiquotes']\n",
      "Shape: (1000, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "_rid                 0\n",
       "_self                0\n",
       "_etag                0\n",
       "_attachments         0\n",
       "url                  0\n",
       "name                 0\n",
       "type                 0\n",
       "language             7\n",
       "genres               0\n",
       "status               0\n",
       "runtime            179\n",
       "averageRuntime      24\n",
       "premiered           13\n",
       "ended              303\n",
       "officialSite       330\n",
       "schedule             0\n",
       "rating               0\n",
       "weight               0\n",
       "network            199\n",
       "webChannel         796\n",
       "dvdCountry        1000\n",
       "externals            0\n",
       "image               38\n",
       "summary             17\n",
       "updated              0\n",
       "_links               0\n",
       "_embedded            1\n",
       "seasons              0\n",
       "wikipedia_url      661\n",
       "wikiquote_url      860\n",
       "metacritic_url     588\n",
       "eztv_url           359\n",
       "_ts                  0\n",
       "wikipedia          661\n",
       "wikiquotes         907\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am cleaning the columns that I want to use for my prediction model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating_value</th>\n",
       "      <th>release_year</th>\n",
       "      <th>summary_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carol Burnett &amp; Company</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>Music, songs, and comedy sketches.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carla Cametti PD</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>This six-part Australian crime series is cente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Carol Burnett Show</td>\n",
       "      <td>[Comedy, Music]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>CBS brought back The Carol Burnett Show for an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carrier</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>A character-driven immersion in the high-stake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carnival Cravings with Anthony Anderson</td>\n",
       "      <td>[Food]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>There isn't much you can't wrap with bacon or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name           genres  rating_value  \\\n",
       "0                  Carol Burnett & Company         [Comedy]           NaN   \n",
       "1                         Carla Cametti PD               []           NaN   \n",
       "2                   The Carol Burnett Show  [Comedy, Music]           NaN   \n",
       "3                                  Carrier               []           NaN   \n",
       "4  Carnival Cravings with Anthony Anderson           [Food]           NaN   \n",
       "\n",
       "   release_year                                      summary_clean  \n",
       "0        1979.0                 Music, songs, and comedy sketches.  \n",
       "1        2009.0  This six-part Australian crime series is cente...  \n",
       "2        1991.0  CBS brought back The Carol Burnett Show for an...  \n",
       "3        2008.0  A character-driven immersion in the high-stake...  \n",
       "4        2015.0  There isn't much you can't wrap with bacon or ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text() if isinstance(text, str) else \"\"\n",
    "\n",
    "df[\"summary_clean\"] = df[\"summary\"].apply(clean_html)\n",
    "df[\"rating_value\"] = df[\"rating\"].apply(lambda r: r.get(\"average\") if isinstance(r, dict) else None)\n",
    "df[\"release_year\"] = pd.to_datetime(df[\"premiered\"], errors=\"coerce\").dt.year\n",
    "df[[\"name\", \"genres\", \"rating_value\", \"release_year\", \"summary_clean\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a test in order to see from 1000 samples which are the most common ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', 280),\n",
       " ('Comedy', 249),\n",
       " ('Crime', 125),\n",
       " ('Adventure', 87),\n",
       " ('Action', 86),\n",
       " ('Romance', 71),\n",
       " ('Children', 62),\n",
       " ('Fantasy', 46),\n",
       " ('Thriller', 44),\n",
       " ('Anime', 40)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_counts = Counter()\n",
    "\n",
    "for g_list in df[\"genres\"].dropna():\n",
    "    for genre in g_list:\n",
    "        genre_counts[genre] += 1\n",
    "\n",
    "genre_counts.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Total number of entries\n",
    "total_entries = len(df)\n",
    "\n",
    "# Count of missing or empty ratings\n",
    "missing_ratings = df[\"rating_value\"].isna().sum()\n",
    "\n",
    "print(f\"üî¢ Total entries in dataset: {total_entries}\")\n",
    "print(f\"‚ùå Entries with missing ratings: {missing_ratings}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
